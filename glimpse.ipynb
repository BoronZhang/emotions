{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"WESAD/S3/S3_n0.pkl\", 'rb') as file:\n",
    "    data = pickle.load(file, encoding='bytes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrist_ACC: (2930, 3, 32)\n",
      "wrist_BVP: (2930, 1, 64)\n",
      "wrist_EDA: (2930, 1, 4)\n",
      "wrist_TEMP: (2930, 1, 4)\n",
      "chest_ACC: (2930, 3, 700)\n",
      "chest_ECG: (2930, 1, 700)\n",
      "chest_EMG: (2930, 1, 700)\n",
      "chest_EDA: (2930, 1, 700)\n",
      "chest_Temp: (2930, 1, 700)\n",
      "chest_Resp: (2930, 1, 700)\n"
     ]
    }
   ],
   "source": [
    "for device in ['wrist', 'chest']:\n",
    "    for sensor in data[device]:\n",
    "        print(f'{device}_{sensor}: {data[device][sensor].shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def process_input(data, window_size, batch_size, stride=1):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    -----\n",
    "    `data`\n",
    "    `window_size`\n",
    "    `batch_size`\n",
    "    `stride`\n",
    "\n",
    "    Returns\n",
    "    -----\n",
    "    yields a numpy array of size (`batch_size`, `window_size`, `in_channels`)\n",
    "    where `in_channels` is the length of each of the rows of the `data`\n",
    "    \"\"\"\n",
    "    for i in range(0, len(data), stride * batch_size):\n",
    "        yield np.array([data[j * stride:j*stride+window_size] for j in range(i, i+batch_size)])\n",
    "\n",
    "def process_target\n",
    "\n",
    "eee = process_input(data['wrist']['BVP'], 3, 5)\n",
    "fff = process_input(data['label'], 3, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 3, 1, 64) (5, 3, 700)\n",
      "[[[[-1.5800e+01 -6.0000e-02  1.1930e+01  1.8110e+01  1.8220e+01\n",
      "     1.4470e+01  1.0030e+01  7.4400e+00  8.0800e+00  1.2040e+01\n",
      "     1.8510e+01  2.6030e+01  3.3000e+01  3.8440e+01  4.1790e+01\n",
      "     4.2440e+01  3.9690e+01  3.3170e+01  2.3150e+01  1.0950e+01\n",
      "    -1.0900e+00 -1.0340e+01 -1.4630e+01 -1.3380e+01 -8.2800e+00\n",
      "    -2.2000e+00  2.2700e+00  3.9000e+00  3.1600e+00  1.6800e+00\n",
      "     1.2300e+00  3.1700e+00  8.0700e+00  1.5250e+01  2.3390e+01\n",
      "     3.0810e+01  3.5660e+01  3.6420e+01  3.2500e+01  2.4650e+01\n",
      "     1.4570e+01  5.2100e+00 -1.9600e+00 -7.2700e+00 -1.2210e+01\n",
      "    -1.8130e+01 -2.5010e+01 -3.0990e+01 -3.3200e+01 -2.9780e+01\n",
      "    -1.9960e+01 -5.8600e+00  8.5900e+00  1.9160e+01  2.2680e+01\n",
      "     1.8040e+01  6.2600e+00 -1.0140e+01 -2.7960e+01 -4.3300e+01\n",
      "    -5.3520e+01 -5.7150e+01 -5.3810e+01 -4.4320e+01]]\n",
      "\n",
      "  [[-3.0710e+01 -1.5790e+01 -2.4100e+00  7.5000e+00  1.3380e+01\n",
      "     1.6080e+01  1.6960e+01  1.7460e+01  1.8590e+01  2.0850e+01\n",
      "     2.4400e+01  2.9060e+01  3.4410e+01  3.9590e+01  4.3240e+01\n",
      "     4.4070e+01  4.1470e+01  3.5750e+01  2.8100e+01  2.0150e+01\n",
      "     1.3470e+01  9.2700e+00  8.0900e+00  9.8800e+00  1.3920e+01\n",
      "     1.8920e+01  2.3120e+01  2.4750e+01  2.2430e+01  1.5420e+01\n",
      "     3.8700e+00 -1.1770e+01 -3.0770e+01 -5.2310e+01 -7.5300e+01\n",
      "    -9.8020e+01 -1.1817e+02 -1.3319e+02 -1.4096e+02 -1.4049e+02\n",
      "    -1.3237e+02 -1.1830e+02 -1.0047e+02 -8.1160e+01 -6.2520e+01\n",
      "    -4.6300e+01 -3.3420e+01 -2.3610e+01 -1.5320e+01 -6.4100e+00\n",
      "     5.9100e+00  2.4490e+01  5.1020e+01  8.4940e+01  1.2291e+02\n",
      "     1.5885e+02  1.8476e+02  1.9264e+02  1.7694e+02  1.3848e+02\n",
      "     8.5090e+01  2.8770e+01 -1.9020e+01 -5.1290e+01]]\n",
      "\n",
      "  [[-6.6580e+01 -6.7370e+01 -5.7480e+01 -4.1100e+01 -2.1530e+01\n",
      "    -2.4500e+00  1.0940e+01  1.3070e+01  1.4800e+00 -2.0020e+01\n",
      "    -4.1190e+01 -4.6980e+01 -2.9830e+01  4.6500e+00  4.3150e+01\n",
      "     7.3390e+01  8.8760e+01  8.8330e+01  7.4890e+01  5.2480e+01\n",
      "     2.7120e+01 -5.0000e-02 -2.6210e+01 -4.6770e+01 -5.7880e+01\n",
      "    -5.8830e+01 -5.2790e+01 -4.5310e+01 -4.1810e+01 -4.5260e+01\n",
      "    -5.5200e+01 -6.7180e+01 -7.3930e+01 -6.8930e+01 -4.9730e+01\n",
      "    -1.9090e+01  1.6410e+01  4.9270e+01  7.4200e+01  8.9070e+01\n",
      "     9.5550e+01  9.7220e+01  9.7040e+01  9.5890e+01  9.2820e+01\n",
      "     8.6300e+01  7.5710e+01  6.2030e+01  4.7150e+01  3.3090e+01\n",
      "     2.0830e+01  9.7000e+00 -1.9000e+00 -1.4970e+01 -2.8940e+01\n",
      "    -4.1380e+01 -4.8930e+01 -4.9340e+01 -4.2740e+01 -3.1850e+01\n",
      "    -2.0750e+01 -1.2860e+01 -9.5400e+00 -9.6500e+00]]]\n",
      "\n",
      "\n",
      " [[[-3.0710e+01 -1.5790e+01 -2.4100e+00  7.5000e+00  1.3380e+01\n",
      "     1.6080e+01  1.6960e+01  1.7460e+01  1.8590e+01  2.0850e+01\n",
      "     2.4400e+01  2.9060e+01  3.4410e+01  3.9590e+01  4.3240e+01\n",
      "     4.4070e+01  4.1470e+01  3.5750e+01  2.8100e+01  2.0150e+01\n",
      "     1.3470e+01  9.2700e+00  8.0900e+00  9.8800e+00  1.3920e+01\n",
      "     1.8920e+01  2.3120e+01  2.4750e+01  2.2430e+01  1.5420e+01\n",
      "     3.8700e+00 -1.1770e+01 -3.0770e+01 -5.2310e+01 -7.5300e+01\n",
      "    -9.8020e+01 -1.1817e+02 -1.3319e+02 -1.4096e+02 -1.4049e+02\n",
      "    -1.3237e+02 -1.1830e+02 -1.0047e+02 -8.1160e+01 -6.2520e+01\n",
      "    -4.6300e+01 -3.3420e+01 -2.3610e+01 -1.5320e+01 -6.4100e+00\n",
      "     5.9100e+00  2.4490e+01  5.1020e+01  8.4940e+01  1.2291e+02\n",
      "     1.5885e+02  1.8476e+02  1.9264e+02  1.7694e+02  1.3848e+02\n",
      "     8.5090e+01  2.8770e+01 -1.9020e+01 -5.1290e+01]]\n",
      "\n",
      "  [[-6.6580e+01 -6.7370e+01 -5.7480e+01 -4.1100e+01 -2.1530e+01\n",
      "    -2.4500e+00  1.0940e+01  1.3070e+01  1.4800e+00 -2.0020e+01\n",
      "    -4.1190e+01 -4.6980e+01 -2.9830e+01  4.6500e+00  4.3150e+01\n",
      "     7.3390e+01  8.8760e+01  8.8330e+01  7.4890e+01  5.2480e+01\n",
      "     2.7120e+01 -5.0000e-02 -2.6210e+01 -4.6770e+01 -5.7880e+01\n",
      "    -5.8830e+01 -5.2790e+01 -4.5310e+01 -4.1810e+01 -4.5260e+01\n",
      "    -5.5200e+01 -6.7180e+01 -7.3930e+01 -6.8930e+01 -4.9730e+01\n",
      "    -1.9090e+01  1.6410e+01  4.9270e+01  7.4200e+01  8.9070e+01\n",
      "     9.5550e+01  9.7220e+01  9.7040e+01  9.5890e+01  9.2820e+01\n",
      "     8.6300e+01  7.5710e+01  6.2030e+01  4.7150e+01  3.3090e+01\n",
      "     2.0830e+01  9.7000e+00 -1.9000e+00 -1.4970e+01 -2.8940e+01\n",
      "    -4.1380e+01 -4.8930e+01 -4.9340e+01 -4.2740e+01 -3.1850e+01\n",
      "    -2.0750e+01 -1.2860e+01 -9.5400e+00 -9.6500e+00]]\n",
      "\n",
      "  [[-1.2320e+01 -1.7200e+01 -2.4050e+01 -3.2400e+01 -4.1610e+01\n",
      "    -5.1030e+01 -6.0040e+01 -6.8400e+01 -7.6540e+01 -8.4200e+01\n",
      "    -8.8990e+01 -8.6210e+01 -7.0780e+01 -4.0310e+01  2.0600e+00\n",
      "     4.7600e+01  8.6990e+01  1.1125e+02  1.1583e+02  1.0244e+02\n",
      "     7.7630e+01  4.9290e+01  2.3260e+01  1.4800e+00 -1.6670e+01\n",
      "    -3.2430e+01 -4.6280e+01 -5.7200e+01 -6.3460e+01 -6.4290e+01\n",
      "    -6.0960e+01 -5.4560e+01 -4.8220e+01 -4.4560e+01 -4.4550e+01\n",
      "    -4.7600e+01 -5.1790e+01 -5.4810e+01 -5.4850e+01 -5.1150e+01\n",
      "    -4.3800e+01 -3.3610e+01 -2.1250e+01 -7.3800e+00  6.9900e+00\n",
      "     2.0400e+01  3.1070e+01  3.7600e+01  3.9630e+01  3.8240e+01\n",
      "     3.5280e+01  3.2690e+01  3.1460e+01  3.1170e+01  3.0580e+01\n",
      "     2.8410e+01  2.3960e+01  1.7070e+01  7.8800e+00 -3.6100e+00\n",
      "    -1.7140e+01 -3.1700e+01 -4.5410e+01 -5.5870e+01]]]\n",
      "\n",
      "\n",
      " [[[-6.6580e+01 -6.7370e+01 -5.7480e+01 -4.1100e+01 -2.1530e+01\n",
      "    -2.4500e+00  1.0940e+01  1.3070e+01  1.4800e+00 -2.0020e+01\n",
      "    -4.1190e+01 -4.6980e+01 -2.9830e+01  4.6500e+00  4.3150e+01\n",
      "     7.3390e+01  8.8760e+01  8.8330e+01  7.4890e+01  5.2480e+01\n",
      "     2.7120e+01 -5.0000e-02 -2.6210e+01 -4.6770e+01 -5.7880e+01\n",
      "    -5.8830e+01 -5.2790e+01 -4.5310e+01 -4.1810e+01 -4.5260e+01\n",
      "    -5.5200e+01 -6.7180e+01 -7.3930e+01 -6.8930e+01 -4.9730e+01\n",
      "    -1.9090e+01  1.6410e+01  4.9270e+01  7.4200e+01  8.9070e+01\n",
      "     9.5550e+01  9.7220e+01  9.7040e+01  9.5890e+01  9.2820e+01\n",
      "     8.6300e+01  7.5710e+01  6.2030e+01  4.7150e+01  3.3090e+01\n",
      "     2.0830e+01  9.7000e+00 -1.9000e+00 -1.4970e+01 -2.8940e+01\n",
      "    -4.1380e+01 -4.8930e+01 -4.9340e+01 -4.2740e+01 -3.1850e+01\n",
      "    -2.0750e+01 -1.2860e+01 -9.5400e+00 -9.6500e+00]]\n",
      "\n",
      "  [[-1.2320e+01 -1.7200e+01 -2.4050e+01 -3.2400e+01 -4.1610e+01\n",
      "    -5.1030e+01 -6.0040e+01 -6.8400e+01 -7.6540e+01 -8.4200e+01\n",
      "    -8.8990e+01 -8.6210e+01 -7.0780e+01 -4.0310e+01  2.0600e+00\n",
      "     4.7600e+01  8.6990e+01  1.1125e+02  1.1583e+02  1.0244e+02\n",
      "     7.7630e+01  4.9290e+01  2.3260e+01  1.4800e+00 -1.6670e+01\n",
      "    -3.2430e+01 -4.6280e+01 -5.7200e+01 -6.3460e+01 -6.4290e+01\n",
      "    -6.0960e+01 -5.4560e+01 -4.8220e+01 -4.4560e+01 -4.4550e+01\n",
      "    -4.7600e+01 -5.1790e+01 -5.4810e+01 -5.4850e+01 -5.1150e+01\n",
      "    -4.3800e+01 -3.3610e+01 -2.1250e+01 -7.3800e+00  6.9900e+00\n",
      "     2.0400e+01  3.1070e+01  3.7600e+01  3.9630e+01  3.8240e+01\n",
      "     3.5280e+01  3.2690e+01  3.1460e+01  3.1170e+01  3.0580e+01\n",
      "     2.8410e+01  2.3960e+01  1.7070e+01  7.8800e+00 -3.6100e+00\n",
      "    -1.7140e+01 -3.1700e+01 -4.5410e+01 -5.5870e+01]]\n",
      "\n",
      "  [[-6.1080e+01 -6.0360e+01 -5.4640e+01 -4.5910e+01 -3.6170e+01\n",
      "    -2.6420e+01 -1.6470e+01 -5.6700e+00  6.2100e+00  1.8270e+01\n",
      "     2.8560e+01  3.4680e+01  3.4830e+01  2.8410e+01  1.6230e+01\n",
      "     3.0000e-02 -1.8340e+01 -3.7670e+01 -5.7590e+01 -7.8050e+01\n",
      "    -9.8450e+01 -1.1683e+02 -1.2986e+02 -1.3362e+02 -1.2512e+02\n",
      "    -1.0366e+02 -7.1610e+01 -3.3890e+01  3.4900e+00  3.5460e+01\n",
      "     5.9380e+01  7.5600e+01  8.6640e+01  9.5430e+01  1.0359e+02\n",
      "     1.1012e+02  1.1151e+02  1.0321e+02  8.1570e+01  4.5710e+01\n",
      "    -1.7400e+00 -5.5360e+01 -1.0860e+02 -1.5548e+02 -1.9166e+02\n",
      "    -2.1452e+02 -2.2282e+02 -2.1633e+02 -1.9572e+02 -1.6278e+02\n",
      "    -1.2054e+02 -7.2940e+01 -2.4120e+01  2.2370e+01  6.4190e+01\n",
      "     1.0011e+02  1.2960e+02  1.5226e+02  1.6752e+02  1.7472e+02\n",
      "     1.7349e+02  1.6432e+02  1.4863e+02  1.2881e+02]]]\n",
      "\n",
      "\n",
      " [[[-1.2320e+01 -1.7200e+01 -2.4050e+01 -3.2400e+01 -4.1610e+01\n",
      "    -5.1030e+01 -6.0040e+01 -6.8400e+01 -7.6540e+01 -8.4200e+01\n",
      "    -8.8990e+01 -8.6210e+01 -7.0780e+01 -4.0310e+01  2.0600e+00\n",
      "     4.7600e+01  8.6990e+01  1.1125e+02  1.1583e+02  1.0244e+02\n",
      "     7.7630e+01  4.9290e+01  2.3260e+01  1.4800e+00 -1.6670e+01\n",
      "    -3.2430e+01 -4.6280e+01 -5.7200e+01 -6.3460e+01 -6.4290e+01\n",
      "    -6.0960e+01 -5.4560e+01 -4.8220e+01 -4.4560e+01 -4.4550e+01\n",
      "    -4.7600e+01 -5.1790e+01 -5.4810e+01 -5.4850e+01 -5.1150e+01\n",
      "    -4.3800e+01 -3.3610e+01 -2.1250e+01 -7.3800e+00  6.9900e+00\n",
      "     2.0400e+01  3.1070e+01  3.7600e+01  3.9630e+01  3.8240e+01\n",
      "     3.5280e+01  3.2690e+01  3.1460e+01  3.1170e+01  3.0580e+01\n",
      "     2.8410e+01  2.3960e+01  1.7070e+01  7.8800e+00 -3.6100e+00\n",
      "    -1.7140e+01 -3.1700e+01 -4.5410e+01 -5.5870e+01]]\n",
      "\n",
      "  [[-6.1080e+01 -6.0360e+01 -5.4640e+01 -4.5910e+01 -3.6170e+01\n",
      "    -2.6420e+01 -1.6470e+01 -5.6700e+00  6.2100e+00  1.8270e+01\n",
      "     2.8560e+01  3.4680e+01  3.4830e+01  2.8410e+01  1.6230e+01\n",
      "     3.0000e-02 -1.8340e+01 -3.7670e+01 -5.7590e+01 -7.8050e+01\n",
      "    -9.8450e+01 -1.1683e+02 -1.2986e+02 -1.3362e+02 -1.2512e+02\n",
      "    -1.0366e+02 -7.1610e+01 -3.3890e+01  3.4900e+00  3.5460e+01\n",
      "     5.9380e+01  7.5600e+01  8.6640e+01  9.5430e+01  1.0359e+02\n",
      "     1.1012e+02  1.1151e+02  1.0321e+02  8.1570e+01  4.5710e+01\n",
      "    -1.7400e+00 -5.5360e+01 -1.0860e+02 -1.5548e+02 -1.9166e+02\n",
      "    -2.1452e+02 -2.2282e+02 -2.1633e+02 -1.9572e+02 -1.6278e+02\n",
      "    -1.2054e+02 -7.2940e+01 -2.4120e+01  2.2370e+01  6.4190e+01\n",
      "     1.0011e+02  1.2960e+02  1.5226e+02  1.6752e+02  1.7472e+02\n",
      "     1.7349e+02  1.6432e+02  1.4863e+02  1.2881e+02]]\n",
      "\n",
      "  [[ 1.0775e+02  8.8220e+01  7.2470e+01  6.1950e+01  5.7160e+01\n",
      "     5.7590e+01  6.1600e+01  6.6550e+01  6.9480e+01  6.8120e+01\n",
      "     6.2080e+01  5.3290e+01  4.5470e+01  4.2660e+01  4.7370e+01\n",
      "     5.9480e+01  7.6090e+01  9.2630e+01  1.0453e+02  1.0841e+02\n",
      "     1.0270e+02  8.7480e+01  6.4210e+01  3.5480e+01  4.9800e+00\n",
      "    -2.2880e+01 -4.3610e+01 -5.3880e+01 -5.2630e+01 -4.1580e+01\n",
      "    -2.4660e+01 -6.6800e+00  8.3800e+00  1.8550e+01  2.4090e+01\n",
      "     2.6780e+01  2.8690e+01  3.1160e+01  3.4460e+01  3.7980e+01\n",
      "     4.0860e+01  4.2470e+01  4.2660e+01  4.1550e+01  3.9350e+01\n",
      "     3.6100e+01  3.1700e+01  2.6100e+01  1.9460e+01  1.2290e+01\n",
      "     5.2300e+00 -1.1000e+00 -6.4100e+00 -1.0720e+01 -1.4250e+01\n",
      "    -1.7120e+01 -1.9130e+01 -1.9900e+01 -1.9110e+01 -1.6660e+01\n",
      "    -1.2780e+01 -7.9300e+00 -2.6600e+00  2.6000e+00]]]\n",
      "\n",
      "\n",
      " [[[-6.1080e+01 -6.0360e+01 -5.4640e+01 -4.5910e+01 -3.6170e+01\n",
      "    -2.6420e+01 -1.6470e+01 -5.6700e+00  6.2100e+00  1.8270e+01\n",
      "     2.8560e+01  3.4680e+01  3.4830e+01  2.8410e+01  1.6230e+01\n",
      "     3.0000e-02 -1.8340e+01 -3.7670e+01 -5.7590e+01 -7.8050e+01\n",
      "    -9.8450e+01 -1.1683e+02 -1.2986e+02 -1.3362e+02 -1.2512e+02\n",
      "    -1.0366e+02 -7.1610e+01 -3.3890e+01  3.4900e+00  3.5460e+01\n",
      "     5.9380e+01  7.5600e+01  8.6640e+01  9.5430e+01  1.0359e+02\n",
      "     1.1012e+02  1.1151e+02  1.0321e+02  8.1570e+01  4.5710e+01\n",
      "    -1.7400e+00 -5.5360e+01 -1.0860e+02 -1.5548e+02 -1.9166e+02\n",
      "    -2.1452e+02 -2.2282e+02 -2.1633e+02 -1.9572e+02 -1.6278e+02\n",
      "    -1.2054e+02 -7.2940e+01 -2.4120e+01  2.2370e+01  6.4190e+01\n",
      "     1.0011e+02  1.2960e+02  1.5226e+02  1.6752e+02  1.7472e+02\n",
      "     1.7349e+02  1.6432e+02  1.4863e+02  1.2881e+02]]\n",
      "\n",
      "  [[ 1.0775e+02  8.8220e+01  7.2470e+01  6.1950e+01  5.7160e+01\n",
      "     5.7590e+01  6.1600e+01  6.6550e+01  6.9480e+01  6.8120e+01\n",
      "     6.2080e+01  5.3290e+01  4.5470e+01  4.2660e+01  4.7370e+01\n",
      "     5.9480e+01  7.6090e+01  9.2630e+01  1.0453e+02  1.0841e+02\n",
      "     1.0270e+02  8.7480e+01  6.4210e+01  3.5480e+01  4.9800e+00\n",
      "    -2.2880e+01 -4.3610e+01 -5.3880e+01 -5.2630e+01 -4.1580e+01\n",
      "    -2.4660e+01 -6.6800e+00  8.3800e+00  1.8550e+01  2.4090e+01\n",
      "     2.6780e+01  2.8690e+01  3.1160e+01  3.4460e+01  3.7980e+01\n",
      "     4.0860e+01  4.2470e+01  4.2660e+01  4.1550e+01  3.9350e+01\n",
      "     3.6100e+01  3.1700e+01  2.6100e+01  1.9460e+01  1.2290e+01\n",
      "     5.2300e+00 -1.1000e+00 -6.4100e+00 -1.0720e+01 -1.4250e+01\n",
      "    -1.7120e+01 -1.9130e+01 -1.9900e+01 -1.9110e+01 -1.6660e+01\n",
      "    -1.2780e+01 -7.9300e+00 -2.6600e+00  2.6000e+00]]\n",
      "\n",
      "  [[ 7.5400e+00  1.2070e+01  1.6130e+01  1.9660e+01  2.2630e+01\n",
      "     2.5090e+01  2.7100e+01  2.8700e+01  2.9820e+01  3.0320e+01\n",
      "     3.0200e+01  2.9460e+01  2.8110e+01  2.6260e+01  2.4200e+01\n",
      "     2.2240e+01  2.0640e+01  1.9460e+01  1.8540e+01  1.7960e+01\n",
      "     1.7460e+01  1.6500e+01  1.4500e+01  1.1290e+01  7.1300e+00\n",
      "     2.5000e+00 -2.0600e+00 -6.1200e+00 -8.6200e+00 -9.1900e+00\n",
      "    -8.3600e+00 -7.0600e+00 -5.8900e+00 -4.9900e+00 -4.2100e+00\n",
      "    -3.2800e+00 -1.8100e+00  1.9500e+00  8.8200e+00  1.8120e+01\n",
      "     2.8130e+01  3.7180e+01  4.4030e+01  4.7980e+01  4.8940e+01\n",
      "     4.7450e+01  4.5990e+01  4.5900e+01  4.6590e+01  4.6510e+01\n",
      "     4.4750e+01  4.1560e+01  3.7850e+01  3.4630e+01  2.1750e+01\n",
      "    -2.9300e+00 -3.3300e+01 -6.1110e+01 -8.2690e+01 -9.8170e+01\n",
      "    -1.0852e+02 -1.1428e+02 -1.1569e+02 -1.1329e+02]]]]\n",
      "[[[1 1 1 ... 1 1 1]\n",
      "  [1 1 1 ... 1 1 1]\n",
      "  [1 1 1 ... 1 1 1]]\n",
      "\n",
      " [[1 1 1 ... 1 1 1]\n",
      "  [1 1 1 ... 1 1 1]\n",
      "  [1 1 1 ... 1 1 1]]\n",
      "\n",
      " [[1 1 1 ... 1 1 1]\n",
      "  [1 1 1 ... 1 1 1]\n",
      "  [1 1 1 ... 1 1 1]]\n",
      "\n",
      " [[1 1 1 ... 1 1 1]\n",
      "  [1 1 1 ... 1 1 1]\n",
      "  [1 1 1 ... 1 1 1]]\n",
      "\n",
      " [[1 1 1 ... 1 1 1]\n",
      "  [1 1 1 ... 1 1 1]\n",
      "  [1 1 1 ... 1 1 1]]]\n"
     ]
    }
   ],
   "source": [
    "data_inp = next(eee)\n",
    "data_target = next(fff)\n",
    "print(data_inp.shape, data_target.shape)\n",
    "print(data_inp)\n",
    "print(data_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data of S2 loaded!\n",
      "Data of S3 loaded!\n",
      "Data of S4 loaded!\n",
      "Data of S5 loaded!\n",
      "Data of S6 loaded!\n",
      "Data of S7 loaded!\n",
      "Data of S8 loaded!\n",
      "Data of S9 loaded!\n",
      "Data of S10 loaded!\n",
      "Data of S11 loaded!\n",
      "Data of S13 loaded!\n",
      "Data of S14 loaded!\n",
      "Data of S15 loaded!\n",
      "Data of S16 loaded!\n",
      "Data of S17 loaded!\n"
     ]
    }
   ],
   "source": [
    "# Creating dataframe of all of them\n",
    "# `window` | `mean` | `std` | `max` | `min` | `label`\n",
    "\n",
    "from feature import extract_features\n",
    "\n",
    "extract_features(verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject #S9 data loadedd\n",
      "data frames concated successfully\n",
      "Training GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
      "             param_grid={'min_samples_leaf': [1, 5], 'n_estimators': [50, 100]},\n",
      "             scoring='f1_macro')\n",
      "Training GridSearchCV(cv=5, estimator=SVC(), param_grid={}, scoring='f1_macro')\n",
      "Training GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
      "             param_grid={'n_neighbors': [3, 5, 7]}, scoring='f1_macro')\n",
      "Sensor chest_ACC done!\n",
      "Training GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
      "             param_grid={'min_samples_leaf': [1, 5], 'n_estimators': [50, 100]},\n",
      "             scoring='f1_macro')\n",
      "Training GridSearchCV(cv=5, estimator=SVC(), param_grid={}, scoring='f1_macro')\n",
      "Training GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
      "             param_grid={'n_neighbors': [3, 5, 7]}, scoring='f1_macro')\n",
      "Sensor chest_ECG done!\n",
      "Training GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
      "             param_grid={'min_samples_leaf': [1, 5], 'n_estimators': [50, 100]},\n",
      "             scoring='f1_macro')\n",
      "Training GridSearchCV(cv=5, estimator=SVC(), param_grid={}, scoring='f1_macro')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from training import WESADTrainer\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "trainer = WESADTrainer({\n",
    "    RandomForestClassifier: \n",
    "        {'n_estimators': [50, 100], 'min_samples_leaf': [1, 5]},\n",
    "    SVC:\n",
    "        {},\n",
    "    KNeighborsClassifier:\n",
    "        {'n_neighbors': [3, 5, 7]},\n",
    "    })\n",
    "\n",
    "trainer.load_data(verbose=1)\n",
    "trainer.fit(verbose=2)\n",
    "reports = trainer.report()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.7042\n",
      "Epoch [2/10], Loss: 0.6921\n",
      "Epoch [3/10], Loss: 0.6927\n",
      "Epoch [4/10], Loss: 0.6929\n",
      "Epoch [5/10], Loss: 0.6930\n",
      "Epoch [6/10], Loss: 0.6930\n",
      "Epoch [7/10], Loss: 0.6930\n",
      "Epoch [8/10], Loss: 0.6928\n",
      "Epoch [9/10], Loss: 0.6920\n",
      "Epoch [10/10], Loss: 0.6855\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from neuralNet import NeuralNet1, Trainer\n",
    "\n",
    "\n",
    "window_size = 30 * 64\n",
    "num_classes = 2\n",
    "# Dummy input tensor: batch_size x sequence_length x input_size\n",
    "# Dummy target tensor: batch_size\n",
    "dummy_input = torch.from_numpy(np.random.rand(100, window_size).astype(np.float32))\n",
    "dummy_target = torch.randint(0, num_classes, (100,)).type(torch.float32)\n",
    "\n",
    "with open(\"WESAD/S3/S3_n0.pkl\", 'rb') as file:\n",
    "    data = pickle.load(file, encoding='bytes')\n",
    "\n",
    "\n",
    "trainer = Trainer(data['wrist']['BVP'], data['labels'], window_size)\n",
    "trainer.go()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int8)\n"
     ]
    }
   ],
   "source": [
    "print(outputs.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['1', '2', '3', '4', 'accuracy', 'macro avg', 'weighted avg'])\n",
      "RandomForestClassifier(min_samples_leaf=3, n_estimators=50)\n",
      "\tf1 = 0.9807683748786241, and 0.9792757747334849\n",
      "RandomForestClassifier(min_samples_leaf=3)\n",
      "\tf1 = 0.9793656302075824, and 0.9783892499107899\n",
      "RandomForestClassifier(min_samples_leaf=5, n_estimators=50)\n",
      "\tf1 = 0.9765784907752294, and 0.9752264184563383\n",
      "RandomForestClassifier(min_samples_leaf=5)\n",
      "\tf1 = 0.9765604908168566, and 0.9752194774008438\n",
      "RandomForestClassifier(min_samples_leaf=10, n_estimators=50)\n",
      "\tf1 = 0.97662241780243, and 0.9758795434670711\n",
      "RandomForestClassifier(min_samples_leaf=10)\n",
      "\tf1 = 0.9751966338076336, and 0.9748985584214283\n",
      "RandomForestClassifier(criterion='entropy', min_samples_leaf=3, n_estimators=50)\n",
      "\tf1 = 0.9793618785767938, and 0.9774134575418839\n",
      "RandomForestClassifier(criterion='entropy', min_samples_leaf=3)\n",
      "\tf1 = 0.9793656302075824, and 0.9783892499107899\n",
      "RandomForestClassifier(criterion='entropy', min_samples_leaf=5, n_estimators=50)\n",
      "\tf1 = 0.9780043320978077, and 0.9762074397327382\n",
      "RandomForestClassifier(criterion='entropy', min_samples_leaf=5)\n",
      "\tf1 = 0.9793618785767938, and 0.9774134575418839\n",
      "RandomForestClassifier(criterion='entropy', min_samples_leaf=10,\n",
      "                       n_estimators=50)\n",
      "\tf1 = 0.97662241780243, and 0.9758795434670711\n",
      "RandomForestClassifier(criterion='entropy', min_samples_leaf=10)\n",
      "\tf1 = 0.9765823553138298, and 0.9759910823971282\n",
      "SVC()\n",
      "\tf1 = 0.9656353381220765, and 0.9618114187087513\n",
      "KNeighborsClassifier(n_neighbors=3)\n",
      "\tf1 = 0.9711320809914304, and 0.9720674662156576\n",
      "KNeighborsClassifier()\n",
      "\tf1 = 0.9766281624663369, and 0.9770265754069533\n",
      "KNeighborsClassifier(n_neighbors=7)\n",
      "\tf1 = 0.9752471942023945, and 0.9759370292353194\n"
     ]
    }
   ],
   "source": [
    "# Reports\n",
    "for model in reports:\n",
    "    print(model)\n",
    "    f11 = reports[model]['weighted avg']['f1-score']\n",
    "    f12 = reports[model]['macro avg']['f1-score']\n",
    "    print(f'\\tf1 = {f11}, and {f12}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aaa(i, j):\n",
    "    for k in range(i, j):\n",
    "        yield k\n",
    "\n",
    "x = aaa(0, 10)\n",
    "y = aaa(10, 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 12\n"
     ]
    }
   ],
   "source": [
    "print(next(x), next(y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
