{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrist_ACC: (2930, 3, 32)\n",
      "wrist_BVP: (2930, 1, 64)\n",
      "wrist_EDA: (2930, 1, 4)\n",
      "wrist_TEMP: (2930, 1, 4)\n",
      "chest_ACC: (2930, 3, 700)\n",
      "chest_ECG: (2930, 1, 700)\n",
      "chest_EMG: (2930, 1, 700)\n",
      "chest_EDA: (2930, 1, 700)\n",
      "chest_Temp: (2930, 1, 700)\n",
      "chest_Resp: (2930, 1, 700)\n"
     ]
    }
   ],
   "source": [
    "with open(\"WESAD/S3/S3_n0.pkl\", 'rb') as file:\n",
    "    data = pickle.load(file, encoding='bytes')\n",
    "for device in ['wrist', 'chest']:\n",
    "    for sensor in data[device]:\n",
    "        print(f'{device}_{sensor}: {data[device][sensor].shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data of S2 loaded!\n",
      "Data of S3 loaded!\n",
      "Data of S4 loaded!\n",
      "Data of S5 loaded!\n",
      "Data of S6 loaded!\n",
      "Data of S7 loaded!\n",
      "Data of S8 loaded!\n",
      "Data of S9 loaded!\n",
      "Data of S10 loaded!\n",
      "Data of S11 loaded!\n",
      "Data of S13 loaded!\n",
      "Data of S14 loaded!\n",
      "Data of S15 loaded!\n",
      "Data of S16 loaded!\n",
      "Data of S17 loaded!\n"
     ]
    }
   ],
   "source": [
    "# Creating dataframe of all of them\n",
    "# `window` | `mean` | `std` | `max` | `min` | `label`\n",
    "\n",
    "from feature import extract_features\n",
    "\n",
    "extract_features(verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing S2\n",
      "test #S2 skipped\n",
      "\n",
      "input of size (42069, 6)\n",
      "Training RandomForestClassifier() completed in 48.474334955215454 secs (score=0.7925797662887943)\n",
      "Training MLPClassifier() completed in 43.78752422332764 secs (score=0.5353593643641084)\n",
      "predicting df of size (2889, 5), made (2889,)\n",
      "Report of S2: {'2': {'precision': 0.8801955990220048, 'recall': 0.5853658536585366, 'f1-score': 0.703125, 'support': 615}, '3': {'precision': 0.8971774193548387, 'recall': 0.9784520668425681, 'f1-score': 0.9360538493899875, 'support': 2274}, 'accuracy': 0.894773277950848, 'macro avg': {'precision': 0.8886865091884217, 'recall': 0.7819089602505523, 'f1-score': 0.8195894246949937, 'support': 2889}, 'weighted avg': {'precision': 0.8935623901043394, 'recall': 0.894773277950848, 'f1-score': 0.886468787993365, 'support': 2889}}\n",
      "Testing S3\n",
      "test #S3 skipped\n",
      "\n",
      "input of size (42023, 6)\n",
      "Training RandomForestClassifier() completed in 54.44404602050781 secs (score=0.7964324970362877)\n",
      "Training MLPClassifier() completed in 45.557555198669434 secs (score=0.5922068807119566)\n",
      "predicting df of size (2935, 5), made (2935,)\n",
      "Report of S3: {'2': {'precision': 1.0, 'recall': 0.5625, 'f1-score': 0.72, 'support': 640}, '3': {'precision': 0.8912621359223301, 'recall': 1.0, 'f1-score': 0.9425051334702258, 'support': 2295}, 'accuracy': 0.9045996592844975, 'macro avg': {'precision': 0.945631067961165, 'recall': 0.78125, 'f1-score': 0.8312525667351129, 'support': 2935}, 'weighted avg': {'precision': 0.9149732885661832, 'recall': 0.9045996592844975, 'f1-score': 0.8939861265124934, 'support': 2935}}\n",
      "Testing S4\n",
      "test #S4 skipped\n",
      "\n",
      "input of size (41988, 6)\n",
      "Training RandomForestClassifier() completed in 55.636016845703125 secs (score=0.8072915938366891)\n",
      "Training MLPClassifier() completed in 46.71273136138916 secs (score=0.5686435901747865)\n",
      "predicting df of size (2970, 5), made (2970,)\n",
      "Report of S4: {'2': {'precision': 0.5578800557880056, 'recall': 0.6299212598425197, 'f1-score': 0.591715976331361, 'support': 635}, '3': {'precision': 0.8956946293830448, 'recall': 0.8642398286937901, 'f1-score': 0.8796861377506537, 'support': 2335}, 'accuracy': 0.8141414141414142, 'macro avg': {'precision': 0.7267873425855251, 'recall': 0.747080544268155, 'f1-score': 0.7357010570410074, 'support': 2970}, 'weighted avg': {'precision': 0.823468281156496, 'recall': 0.8141414141414142, 'f1-score': 0.8181167598041046, 'support': 2970}}\n",
      "Testing S5\n",
      "test #S5 skipped\n",
      "\n",
      "input of size (41947, 6)\n",
      "Training RandomForestClassifier() completed in 52.36353158950806 secs (score=0.8088790032094405)\n",
      "Training MLPClassifier() completed in 60.37564444541931 secs (score=0.549971132463254)\n",
      "predicting df of size (3011, 5), made (3011,)\n",
      "Report of S5: {'2': {'precision': 0.5472392638036809, 'recall': 0.6914728682170542, 'f1-score': 0.610958904109589, 'support': 645}, '3': {'precision': 0.9093806921675774, 'recall': 0.8440405748098055, 'f1-score': 0.8754932047347654, 'support': 2366}, 'accuracy': 0.811358352706742, 'macro avg': {'precision': 0.7283099779856292, 'recall': 0.7677567215134299, 'f1-score': 0.7432260544221772, 'support': 3011}, 'weighted avg': {'precision': 0.8318047302629897, 'recall': 0.811358352706742, 'f1-score': 0.8188261094497309, 'support': 3011}}\n",
      "Testing S6\n",
      "test #S6 skipped\n",
      "\n",
      "input of size (41969, 6)\n",
      "Training RandomForestClassifier() completed in 52.84859561920166 secs (score=0.8033373567356599)\n",
      "Training MLPClassifier() completed in 53.31463956832886 secs (score=0.5114351382166007)\n",
      "predicting df of size (2989, 5), made (2989,)\n",
      "Report of S6: {'2': {'precision': 1.0, 'recall': 0.42153846153846153, 'f1-score': 0.593073593073593, 'support': 650}, '3': {'precision': 0.8615101289134438, 'recall': 1.0, 'f1-score': 0.925603482390186, 'support': 2339}, 'accuracy': 0.8742054198728672, 'macro avg': {'precision': 0.930755064456722, 'recall': 0.7107692307692308, 'f1-score': 0.7593385377318895, 'support': 2989}, 'weighted avg': {'precision': 0.8916266950580611, 'recall': 0.8742054198728672, 'f1-score': 0.8532901909697157, 'support': 2989}}\n",
      "Testing S7\n",
      "test #S7 skipped\n",
      "\n",
      "input of size (41970, 6)\n",
      "Training RandomForestClassifier() completed in 51.078453540802 secs (score=0.8052658281806488)\n",
      "Training MLPClassifier() completed in 82.62607336044312 secs (score=0.5272238517196958)\n",
      "predicting df of size (2988, 5), made (2988,)\n",
      "Report of S7: {'2': {'precision': 0.7583732057416268, 'recall': 0.990625, 'f1-score': 0.859078590785908, 'support': 640}, '3': {'precision': 0.9972118959107806, 'recall': 0.91396933560477, 'f1-score': 0.9537777777777777, 'support': 2348}, 'accuracy': 0.9303882195448461, 'macro avg': {'precision': 0.8777925508262037, 'recall': 0.952297167802385, 'f1-score': 0.9064281842818429, 'support': 2988}, 'weighted avg': {'precision': 0.9460550144823141, 'recall': 0.9303882195448461, 'f1-score': 0.9334941500419021, 'support': 2988}}\n",
      "Testing S8\n",
      "test #S8 skipped\n",
      "\n",
      "input of size (41953, 6)\n",
      "Training RandomForestClassifier() completed in 53.94558095932007 secs (score=0.80607507250872)\n",
      "Training MLPClassifier() completed in 80.68179965019226 secs (score=0.5896625130776989)\n",
      "predicting df of size (3005, 5), made (3005,)\n",
      "Report of S8: {'2': {'precision': 0.7137809187279152, 'recall': 0.9044776119402985, 'f1-score': 0.7978933508887425, 'support': 670}, '3': {'precision': 0.9703153988868275, 'recall': 0.89593147751606, 'f1-score': 0.931641059897573, 'support': 2335}, 'accuracy': 0.8978369384359401, 'macro avg': {'precision': 0.8420481588073714, 'recall': 0.9002045447281792, 'f1-score': 0.8647672053931577, 'support': 3005}, 'weighted avg': {'precision': 0.9131180272706972, 'recall': 0.8978369384359401, 'f1-score': 0.9018204392533412, 'support': 3005}}\n",
      "Testing S9\n",
      "test #S9 skipped\n",
      "\n",
      "input of size (41968, 6)\n",
      "Training RandomForestClassifier() completed in 53.17934989929199 secs (score=0.8263158232876083)\n",
      "Training MLPClassifier() completed in 64.01237964630127 secs (score=0.5690492431252364)\n",
      "predicting df of size (2990, 5), made (2990,)\n",
      "Report of S9: {'2': {'precision': 0.3893905191873589, 'recall': 0.5348837209302325, 'f1-score': 0.4506858262573481, 'support': 645}, '3': {'precision': 0.8574144486692015, 'recall': 0.7692963752665245, 'f1-score': 0.8109687570240502, 'support': 2345}, 'accuracy': 0.7187290969899666, 'macro avg': {'precision': 0.6234024839282801, 'recall': 0.6520900480983784, 'f1-score': 0.6308272916406992, 'support': 2990}, 'weighted avg': {'precision': 0.7564527648846567, 'recall': 0.7187290969899666, 'f1-score': 0.733248860587755, 'support': 2990}}\n",
      "Testing S10\n",
      "test #S10 skipped\n",
      "\n",
      "input of size (41885, 6)\n",
      "Training RandomForestClassifier() completed in 49.19394063949585 secs (score=0.8072895017023012)\n",
      "Training MLPClassifier() completed in 40.63723683357239 secs (score=0.5477828315678714)\n",
      "predicting df of size (3073, 5), made (3073,)\n",
      "Report of S10: {'2': {'precision': 0.7775061124694377, 'recall': 0.8772413793103448, 'f1-score': 0.8243681140635126, 'support': 725}, '3': {'precision': 0.9605321507760533, 'recall': 0.9224872231686542, 'f1-score': 0.9411253530306322, 'support': 2348}, 'accuracy': 0.9118125610152945, 'macro avg': {'precision': 0.8690191316227455, 'recall': 0.8998643012394996, 'f1-score': 0.8827467335470724, 'support': 3073}, 'weighted avg': {'precision': 0.9173515852790484, 'recall': 0.9118125610152945, 'f1-score': 0.9135793073908138, 'support': 3073}}\n",
      "Testing S11\n",
      "test #S11 skipped\n",
      "\n",
      "input of size (41939, 6)\n",
      "Training RandomForestClassifier() completed in 49.50080728530884 secs (score=0.831830313007526)\n",
      "Training MLPClassifier() completed in 50.72052454948425 secs (score=0.5574618594138011)\n",
      "predicting df of size (3019, 5), made (3019,)\n",
      "Report of S11: {'2': {'precision': 0.46600741656365885, 'recall': 0.5544117647058824, 'f1-score': 0.5063801208865011, 'support': 680}, '3': {'precision': 0.86289592760181, 'recall': 0.8153056861906798, 'f1-score': 0.8384260276983952, 'support': 2339}, 'accuracy': 0.7565419012918185, 'macro avg': {'precision': 0.6644516720827345, 'recall': 0.6848587254482811, 'f1-score': 0.6724030742924482, 'support': 3019}, 'weighted avg': {'precision': 0.773500701531607, 'recall': 0.7565419012918185, 'f1-score': 0.7636359592545104, 'support': 3019}}\n",
      "Testing S13\n",
      "test #S13 skipped\n",
      "\n",
      "input of size (41937, 6)\n",
      "Training RandomForestClassifier() completed in 48.39837408065796 secs (score=0.8077587163537758)\n",
      "Training MLPClassifier() completed in 55.35606837272644 secs (score=0.5596979768565802)\n",
      "predicting df of size (3021, 5), made (3021,)\n",
      "Report of S13: {'2': {'precision': 0.7024691358024692, 'recall': 0.8569277108433735, 'f1-score': 0.7720488466757124, 'support': 664}, '3': {'precision': 0.9570330167345092, 'recall': 0.8977513788714467, 'f1-score': 0.9264448336252189, 'support': 2357}, 'accuracy': 0.8887785501489573, 'macro avg': {'precision': 0.8297510762684892, 'recall': 0.8773395448574102, 'f1-score': 0.8492468401504656, 'support': 3021}, 'weighted avg': {'precision': 0.9010812070890692, 'recall': 0.8887785501489573, 'f1-score': 0.8925094031934175, 'support': 3021}}\n",
      "Testing S14\n",
      "test #S14 skipped\n",
      "\n",
      "input of size (41937, 6)\n",
      "Training RandomForestClassifier() completed in 48.75162196159363 secs (score=0.8235426110791085)\n",
      "Training MLPClassifier() completed in 48.69660568237305 secs (score=0.5481913886781717)\n",
      "predicting df of size (3021, 5), made (3021,)\n",
      "Report of S14: {'2': {'precision': 0.6002460024600246, 'recall': 0.7229629629629629, 'f1-score': 0.6559139784946236, 'support': 675}, '3': {'precision': 0.9153079710144928, 'recall': 0.861466325660699, 'f1-score': 0.8875713658322354, 'support': 2346}, 'accuracy': 0.8305196954650778, 'macro avg': {'precision': 0.7577769867372587, 'recall': 0.792214644311831, 'f1-score': 0.7717426721634295, 'support': 3021}, 'weighted avg': {'precision': 0.8449118012778936, 'recall': 0.8305196954650778, 'f1-score': 0.8358107777975158, 'support': 3021}}\n",
      "Testing S15\n",
      "test #S15 skipped\n",
      "\n",
      "input of size (41931, 6)\n",
      "Training RandomForestClassifier() completed in 49.67634892463684 secs (score=0.8048664830675982)\n",
      "Training MLPClassifier() completed in 87.33770942687988 secs (score=0.5506953647174019)\n",
      "predicting df of size (3027, 5), made (3027,)\n",
      "Report of S15: {'2': {'precision': 0.7645687645687645, 'recall': 0.956268221574344, 'f1-score': 0.8497409326424871, 'support': 686}, '3': {'precision': 0.9861687413554634, 'recall': 0.9137120888509184, 'f1-score': 0.9485587583148558, 'support': 2341}, 'accuracy': 0.9233564585398084, 'macro avg': {'precision': 0.8753687529621139, 'recall': 0.9349901552126312, 'f1-score': 0.8991498454786715, 'support': 3027}, 'weighted avg': {'precision': 0.9359481982184711, 'recall': 0.9233564585398084, 'f1-score': 0.9261639686183759, 'support': 3027}}\n",
      "Testing S16\n",
      "test #S16 skipped\n",
      "\n",
      "input of size (41945, 6)\n",
      "Training RandomForestClassifier() completed in 69.6068787574768 secs (score=0.8203293927129579)\n",
      "Training MLPClassifier() completed in 68.34525203704834 secs (score=0.5121606596260928)\n",
      "predicting df of size (3013, 5), made (3013,)\n",
      "Report of S16: {'2': {'precision': 0.6277712952158693, 'recall': 0.799405646359584, 'f1-score': 0.7032679738562091, 'support': 673}, '3': {'precision': 0.9373840445269017, 'recall': 0.8636752136752137, 'f1-score': 0.8990213523131673, 'support': 2340}, 'accuracy': 0.8493196150016594, 'macro avg': {'precision': 0.7825776698713856, 'recall': 0.8315404300173989, 'f1-score': 0.8011446630846881, 'support': 3013}, 'weighted avg': {'precision': 0.868227263814547, 'recall': 0.8493196150016594, 'f1-score': 0.8552968173972919, 'support': 3013}}\n",
      "Testing S17\n",
      "test #S17 skipped\n",
      "\n",
      "input of size (41951, 6)\n",
      "Training RandomForestClassifier() completed in 54.125136613845825 secs (score=0.802983847248403)\n",
      "Training MLPClassifier() completed in 61.27843379974365 secs (score=0.6403416358951994)\n",
      "predicting df of size (3007, 5), made (3007,)\n",
      "Report of S17: {'2': {'precision': 0.6605616605616605, 'recall': 0.7482710926694329, 'f1-score': 0.701686121919585, 'support': 723}, '3': {'precision': 0.916819012797075, 'recall': 0.8782837127845884, 'f1-score': 0.8971377459749552, 'support': 2284}, 'accuracy': 0.8470236115729963, 'macro avg': {'precision': 0.7886903366793678, 'recall': 0.8132774027270107, 'f1-score': 0.7994119339472701, 'support': 3007}, 'weighted avg': {'precision': 0.855204757504024, 'recall': 0.8470236115729963, 'f1-score': 0.8501435576836242, 'support': 3007}}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from training import WESADTrainer\n",
    "import pandas as pd\n",
    "\n",
    "subjects = {i for i in range(2, 18)}.difference({12})\n",
    "trainer = WESADTrainer({\n",
    "    RandomForestClassifier: \n",
    "        {'n_estimators': [100], 'min_samples_leaf': [1]},\n",
    "    MLPClassifier:\n",
    "        {},\n",
    "    \n",
    "    }, sensor='chest_Resp', subjects=subjects, data_prefix=\"svd\", classes=[2])\n",
    "\n",
    "reports = trainer.predict_all(verbose=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: {'precision': 0, 'recall': 0, 'f1-score': 0}\n",
      "2: {'precision': 0.6963993299941651, 'recall': 0.7224182369702018, 'f1-score': 0.6893291553323447}\n",
      "3: {'precision': 0.9210738409342901, 'recall': 0.8945740858623811, 'f1-score': 0.9062676559483119}\n",
      "4: {'precision': 0, 'recall': 0, 'f1-score': 0}\n",
      "weighted avg: {'precision': 0.8711524471000265, 'recall': 0.8568923181308491, 'f1-score': 0.8584260810631972}\n",
      "macro avg: {'precision': 0.8087365854642274, 'recall': 0.8084961614162914, 'f1-score': 0.7977984056403286}\n",
      "accuracy: 0.8568923181308491\n"
     ]
    }
   ],
   "source": [
    "for item in reports:\n",
    "    print(f\"{item}: {reports[item]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['wrist', 'chest', 'label'])\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"WESAD/S3/S3_n0.pkl\", \"rb\") as file:\n",
    "    s = pickle.load(file, encoding=\"bytes\")\n",
    "\n",
    "print(s.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['wrist', 'chest', 'label'])\n",
      "wrist_ACC: 3002\n",
      "wrist_BVP: 3002\n",
      "wrist_EDA: 3002\n",
      "wrist_TEMP: 3002\n",
      "chest_ACC: 3002\n",
      "chest_ECG: 3002\n",
      "chest_EMG: 3002\n",
      "chest_EDA: 3002\n",
      "chest_Temp: 3002\n",
      "chest_Resp: 3002\n",
      "labels: (3002, 700)\n",
      "[(1, 3002), (1, 3002), (1, 3002), (1, 3002), (1, 3002), (1, 3002), (1, 3002), (1, 3002), (1, 3002), (1, 3002)]\n",
      "(10, 3002)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "subject = 17\n",
    "with open(f'WESAD/S{subject}/S{subject}_n0.pkl', 'rb') as pklfile:\n",
    "    data = pickle.load(pklfile, encoding='bytes')\n",
    "\n",
    "print(data.keys())\n",
    "for device in ['wrist', 'chest']:\n",
    "    for sensor in data[device].keys():\n",
    "        print(f\"{device}_{sensor}: {len(data[device][sensor])}\")\n",
    "print(f\"labels: {data['label'].shape}\")\n",
    "\n",
    "\n",
    "arrays = [data[device][sensor].mean((1, 2)).reshape(1, -1) for device in ['wrist', 'chest'] for sensor in data[device].keys()]\n",
    "print([a.shape for a in arrays])\n",
    "concated = np.concatenate(arrays)\n",
    "print(concated.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome\n",
      "Dataset: WESAD\n",
      "Nom of:\n",
      "\tTrain: 10\n",
      "\tVal:   4\n",
      "\tTest:  1\n",
      "window size = 10\n",
      "window size = 10\n",
      "window size = 10\n",
      "Size of loader of:\n",
      "\tTrain: 25\n",
      "\tVal:   10\n",
      "\tTest:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name  | Type           | Params\n",
      "-----------------------------------------\n",
      "0 | model | BIOTClassifier | 3.2 M \n",
      "-----------------------------------------\n",
      "3.2 M     Trainable params\n",
      "16        Non-trainable params\n",
      "3.2 M     Total params\n",
      "12.746    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"c:\\Users\\Elham moin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"c:\\Users\\Elham moin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n  File \"c:\\Users\\Elham moin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 316, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n  File \"c:\\Users\\Elham moin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 173, in collate\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"c:\\Users\\Elham moin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 173, in <listcomp>\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"c:\\Users\\Elham moin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 141, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n  File \"c:\\Users\\Elham moin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 212, in collate_tensor_fn\n    out = elem.new(storage).resize_(len(batch), *list(elem.size()))\nRuntimeError: Trying to resize storage that is not resizable\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 22>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     21\u001b[0m args \u001b[38;5;241m=\u001b[39m Args()\n\u001b[1;32m---> 22\u001b[0m \u001b[43msupervised\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Elham moin\\Desktop\\uniVer\\bachProj\\biot\\BIOT\\run_binary_supervised.py:483\u001b[0m, in \u001b[0;36msupervised\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m    470\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[0;32m    471\u001b[0m     devices\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    472\u001b[0m     accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    479\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[early_stop_callback],\n\u001b[0;32m    480\u001b[0m )\n\u001b[0;32m    482\u001b[0m \u001b[38;5;66;03m# train the model\u001b[39;00m\n\u001b[1;32m--> 483\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlightning_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;66;03m# test the model\u001b[39;00m\n\u001b[0;32m    488\u001b[0m pretrain_result \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mtest(\n\u001b[0;32m    489\u001b[0m     model\u001b[38;5;241m=\u001b[39mlightning_model, ckpt_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest\u001b[39m\u001b[38;5;124m\"\u001b[39m, dataloaders\u001b[38;5;241m=\u001b[39mtest_loader\n\u001b[0;32m    490\u001b[0m )[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Elham moin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:544\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 544\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[0;32m    546\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Elham moin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trainer_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[0;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[1;32mc:\\Users\\Elham moin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:580\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    574\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    575\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[0;32m    576\u001b[0m     ckpt_path,\n\u001b[0;32m    577\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    578\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    579\u001b[0m )\n\u001b[1;32m--> 580\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[0;32m    583\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Elham moin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:987\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m    982\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[0;32m    984\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    985\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[0;32m    986\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m--> 987\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    989\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    990\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[0;32m    991\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    992\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Elham moin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1031\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[0;32m   1030\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[1;32m-> 1031\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1032\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m   1033\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_loop\u001b[38;5;241m.\u001b[39mrun()\n",
      "File \u001b[1;32mc:\\Users\\Elham moin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1060\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1057\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1059\u001b[0m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[1;32m-> 1060\u001b[0m \u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1062\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1064\u001b[0m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Elham moin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\loops\\utilities.py:182\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    180\u001b[0m     context_manager \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mno_grad\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[1;32m--> 182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loop_run(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Elham moin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\loops\\evaluation_loop.py:128\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    127\u001b[0m     dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 128\u001b[0m     batch, batch_idx, dataloader_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m previous_dataloader_idx \u001b[38;5;241m!=\u001b[39m dataloader_idx:\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;66;03m# the dataloader has changed, notify the logger connector\u001b[39;00m\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store_dataloader_outputs()\n",
      "File \u001b[1;32mc:\\Users\\Elham moin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\loops\\fetchers.py:133\u001b[0m, in \u001b[0;36m_PrefetchDataFetcher.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatches\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone:\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;66;03m# this will run only when no pre-fetching was done.\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__next__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;66;03m# the iterator is empty\u001b[39;00m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Elham moin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\loops\\fetchers.py:60\u001b[0m, in \u001b[0;36m_DataFetcher.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_profiler()\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 60\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Elham moin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\utilities\\combined_loader.py:341\u001b[0m, in \u001b[0;36mCombinedLoader.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _ITERATOR_RETURN:\n\u001b[0;32m    340\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 341\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    342\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator, _Sequential):\n\u001b[0;32m    343\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\Elham moin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\utilities\\combined_loader.py:142\u001b[0m, in \u001b[0;36m_Sequential.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    139\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 142\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterators\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;66;03m# try the next iterator\u001b[39;00m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_next_iterator()\n",
      "File \u001b[1;32mc:\\Users\\Elham moin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Elham moin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1346\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1345\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[1;32m-> 1346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Elham moin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1372\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[0;32m   1371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[1;32m-> 1372\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1373\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\Elham moin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\_utils.py:705\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    701\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    702\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m--> 705\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"c:\\Users\\Elham moin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"c:\\Users\\Elham moin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n  File \"c:\\Users\\Elham moin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 316, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n  File \"c:\\Users\\Elham moin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 173, in collate\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"c:\\Users\\Elham moin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 173, in <listcomp>\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"c:\\Users\\Elham moin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 141, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n  File \"c:\\Users\\Elham moin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 212, in collate_tensor_fn\n    out = elem.new(storage).resize_(len(batch), *list(elem.size()))\nRuntimeError: Trying to resize storage that is not resizable\n"
     ]
    }
   ],
   "source": [
    "from biot.BIOT.run_binary_supervised import prepare_WESAD_dataloader_manual, supervised\n",
    "\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.epochs = 100\n",
    "        self.lr = 1e-3\n",
    "        self.weight_decay = 1e-5\n",
    "        self.batch_size = 4\n",
    "        self.num_workers = 4\n",
    "        self.dataset = \"WESAD\"\n",
    "        self.model = \"BIOT\"\n",
    "        self.in_channels = 16\n",
    "        self.sample_length = 10\n",
    "        self.n_classes = 1\n",
    "        self.sampling_rate = 200\n",
    "        self.token_size = 200\n",
    "        self.hop_length = 100\n",
    "        self.pretrain_model_path = \"\"\n",
    "        self.server = \"pc\" # or colab\n",
    "        pass\n",
    "\n",
    "args = Args()\n",
    "supervised(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10, 3000])\n",
      "torch.Size([2, 3000])\n"
     ]
    }
   ],
   "source": [
    "for item, label in train:\n",
    "    print(item.shape) # batch_size, channels, freqs\n",
    "    print(label.shape) # batch_size, freqs\n",
    "    break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
